name: Deploy

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:

env:
  PROJECT_ID: ingestaokraken
  REGION: us-central1

jobs:
  deploy-cloud-functions:
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      max-parallel: 1
      matrix:
        include:
          - name: get_stock_data
            entry_point: get_stock_data
            source: functions/get_stock_data
            env: BQ_INTRADAY_DATASET=cotacao_intraday,BQ_DAILY_TABLE=cotacao_ohlcv_diario,BQ_HOLIDAYS_TABLE=feriados_b3
          - name: intraday_candles
            entry_point: generate_intraday_candles
            source: functions/intraday_candles
            env: BQ_INTRADAY_DATASET=cotacao_intraday,BQ_INTRADAY_RAW_TABLE=cotacao_b3,BQ_INTRADAY_15M_TABLE=candles_intraday_15m,BQ_INTRADAY_1H_TABLE=candles_intraday_1h
          - name: eod_signals
            entry_point: generate_eod_signals
            source: functions/eod_signals
            env: BQ_INTRADAY_DATASET=cotacao_intraday,BQ_DAILY_TABLE=cotacao_ohlcv_diario,BQ_SIGNALS_TABLE=sinais_eod,BQ_HOLIDAYS_TABLE=feriados_b3,BQ_BACKTEST_METRICS_TABLE=backtest_metrics
          - name: backtest_daily
            entry_point: backtest_daily
            source: functions/backtest_daily
            env: BQ_INTRADAY_DATASET=cotacao_intraday,BQ_DAILY_TABLE=cotacao_ohlcv_diario,BQ_SIGNALS_TABLE=sinais_eod,BQ_BACKTEST_TRADES_TABLE=backtest_trades,BQ_BACKTEST_METRICS_TABLE=backtest_metrics,BQ_HOLIDAYS_TABLE=feriados_b3
          - name: alerts
            entry_point: alerts
            source: functions/alerts
            env: BQ_INTRADAY_DATASET=cotacao_intraday,BQ_SIGNALS_TABLE=sinais_eod
          - name: dq_checks
            entry_point: dq_checks
            source: functions/dq_checks
            env: BQ_INTRADAY_DATASET=cotacao_intraday,BQ_DAILY_TABLE=cotacao_ohlcv_diario,BQ_INTRADAY_RAW_TABLE=cotacao_b3,BQ_SIGNALS_TABLE=sinais_eod,BQ_BACKTEST_METRICS_TABLE=backtest_metrics,BQ_HOLIDAYS_TABLE=feriados_b3,BQ_DQ_CHECKS_TABLE=dq_checks_daily,BQ_DQ_INCIDENTS_TABLE=dq_incidents,BQ_TICKERS_TABLE=acao_bovespa
    steps:
      - uses: actions/checkout@v4
      - name: Auth GCP
        uses: google-github-actions/auth@v2
        with:
          credentials_json: '${{ secrets.GCP_SA_KEY }}'
          project_id: '${{ env.PROJECT_ID }}'
      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@v2
      - name: Deploy ${{ matrix.name }}
        run: |
          set -o pipefail

          deploy_cmd=(
            gcloud functions deploy "${{ matrix.name }}"
            --runtime python311
            --trigger-http
            --allow-unauthenticated
            --entry-point "${{ matrix.entry_point }}"
            --source "${{ matrix.source }}"
            --project "${PROJECT_ID}"
            --region "${REGION}"
            --set-env-vars="${{ matrix.env }}"
            --quiet
          )

          for attempt in 1 2 3; do
            log_file=$(mktemp)

            set +e
            "${deploy_cmd[@]}" --verbosity=debug --log-http 2>&1 | tee "$log_file"
            status=${PIPESTATUS[0]}
            set -e

            if [ $status -eq 0 ]; then
              rm -f "$log_file"
              break
            fi

            if grep -q "unable to queue the operation" "$log_file" && [ $attempt -lt 3 ]; then
              wait_seconds=$((attempt * 30))
              echo "Deploy returned 409 queue conflict. Retrying in ${wait_seconds}s (attempt ${attempt}/3)."
              rm -f "$log_file"
              sleep $wait_seconds
              continue
            fi

            echo "Deploy command failed with status $status. Last 200 lines of gcloud output:"
            tail -n 200 "$log_file"
            rm -f "$log_file"

            echo "Collecting additional diagnostics for ${{ matrix.name }}..."
            gcloud functions describe "${{ matrix.name }}" \
              --project "${PROJECT_ID}" \
              --region "${REGION}" \
              --gen2 \
              --format=yaml || true

            gcloud run revisions list \
              --project "${PROJECT_ID}" \
              --region "${REGION}" \
              --service "${{ matrix.name }}" \
              --limit=5 || true

            gcloud logging read \
              'resource.type="cloud_run_revision" AND resource.labels.service_name="${{ matrix.name }}"' \
              --project "${PROJECT_ID}" \
              --limit=100 \
              --format="value(timestamp,severity,textPayload,jsonPayload.message)" || true

            exit $status
          done

  deploy-cloud-run:
    runs-on: ubuntu-latest
    needs: deploy-cloud-functions
    steps:
      - uses: actions/checkout@v4
      - name: Auth GCP
        uses: google-github-actions/auth@v2
        with:
          credentials_json: '${{ secrets.GCP_SA_KEY }}'
          project_id: '${{ env.PROJECT_ID }}'
      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@v2
      - name: Deploy google_finance_price
        run: |
          gcloud run deploy google-finance-price             --source functions/google_finance_price             --allow-unauthenticated             --project ${PROJECT_ID}             --region ${REGION}             --set-env-vars=FUNCTION_TARGET=google_finance_price,FUNCTION_SIGNATURE_TYPE=http,BQ_INTRADAY_DATASET=cotacao_intraday,BQ_INTRADAY_RAW_TABLE=cotacao_b3,BQ_HOLIDAYS_TABLE=feriados_b3             --quiet
